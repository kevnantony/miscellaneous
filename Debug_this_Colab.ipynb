{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevnantony/miscellaneous/blob/main/Debug_this_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_MO1qrkiXq9"
      },
      "source": [
        "# Debug this Colab!\n",
        "\n",
        "## Section 1\n",
        "\n",
        "This colab represents a simple ML pipline, loading data, defining a model and fitting the model to the data. It has also been instrumented with Weights and Biases logging tools.\n",
        "\n",
        "At Weights and Biases, we often help our users debug their pipelines -- both the ML code and the logging code from `wandb` integrated into it.\n",
        "\n",
        "Your task is to debug this simple pipeline such that the model is able to learn and <u>perform reasonably well</u> on the given task, without changing the general structure of the model. As you do so, use comments and markdown cells to explain a bit about your process.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR1G4dhwjEM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aaf591e-93cc-4748-dd6c-e567b84e7bfc"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSZcdR1YiZg8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1L3Uvj4jPfa"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxt5CGovi9xF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d12e0dce-b888-4cf2-8b56-0c294b2bafc2"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # CIFAR10 has 3 channels\n",
        "])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Use the defined transform instead of just ToTensor()\n",
        "cifar10 = torchvision.datasets.CIFAR10(root='./data', download=True, transform=transform)\n",
        "pivot = 40000\n",
        "# No need to sort by label - it disrupts the data distribution\n",
        "train_set = torch.utils.data.Subset(cifar10, range(pivot))\n",
        "val_set = torch.utils.data.Subset(cifar10, range(pivot, len(cifar10)))\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)  # No need to shuffle validation data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBD1UVSHjVdp"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)  # CIFAR10 has 3 input channels\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Fixed: MaxPool2d, not MaxPooling2D\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # Fix the calculation for the linear layer input size\n",
        "        # After two conv+pool operations on 32x32 image:\n",
        "        # 32x32 -> conv1 -> 28x28 -> pool -> 14x14 -> conv2 -> 10x10 -> pool -> 5x5\n",
        "        # So with 16 filters, the flattened size is 16*5*5 = 400\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)  # Add an intermediate layer\n",
        "        self.fc3 = nn.Linear(84, 10)  # CIFAR10 has 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)  # Fixed: torch.flatten instead of Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlS39LfBjaGl"
      },
      "source": [
        "# Set reasonable optimization parameters\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Lower the learning rate significantly\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avJhXiz7jpNC"
      },
      "source": [
        "# Training and Validation\n",
        "\n",
        "In this part, you will also need to additionally calculate training and validation accuracy and log it to Weights and Biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjLHeYbBjoQo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "8576ef41-e3ea-4e59-abfe-1fdf5d6f45af"
      },
      "source": [
        "with wandb.init(project='Tier-1-Test', save_code=True) as run:\n",
        "    # Log hyperparameters\n",
        "    wandb.config.update({\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"epochs\": 5,\n",
        "        \"batch_size\": batch_size\n",
        "    })\n",
        "\n",
        "    for epoch in range(5):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for i, data in enumerate(train_loader):\n",
        "            images, labels = data\n",
        "\n",
        "            # Zero the parameter gradients (missing in original)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        # Log training metrics\n",
        "        train_accuracy = 100 * correct_train / total_train\n",
        "        run.log({\n",
        "            'epoch': epoch,\n",
        "            'train_loss': train_loss / len(train_loader),\n",
        "            'train_accuracy': train_accuracy\n",
        "        })\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():  # No gradient calculation during validation\n",
        "            for i, data in enumerate(val_loader):\n",
        "                images, labels = data\n",
        "                outputs = model(images)\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        # Log validation metrics\n",
        "        val_accuracy = 100 * correct_val / total_val\n",
        "        run.log({\n",
        "            'val_loss': val_loss / len(val_loader),\n",
        "            'val_accuracy': val_accuracy\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch+1}: '\n",
        "              f'Train Loss: {train_loss/len(train_loader):.3f}, '\n",
        "              f'Train Acc: {train_accuracy:.1f}%, '\n",
        "              f'Val Loss: {val_loss/len(val_loader):.3f}, '\n",
        "              f'Val Acc: {val_accuracy:.1f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkevinantony\u001b[0m (\u001b[33mkevinantony-nit-jalandhar\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250228_164918-d5a41cpr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/kevinantony-nit-jalandhar/Tier-1-Test/runs/d5a41cpr' target=\"_blank\">polar-terrain-1</a></strong> to <a href='https://wandb.ai/kevinantony-nit-jalandhar/Tier-1-Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/kevinantony-nit-jalandhar/Tier-1-Test' target=\"_blank\">https://wandb.ai/kevinantony-nit-jalandhar/Tier-1-Test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/kevinantony-nit-jalandhar/Tier-1-Test/runs/d5a41cpr' target=\"_blank\">https://wandb.ai/kevinantony-nit-jalandhar/Tier-1-Test/runs/d5a41cpr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.784, Train Acc: 33.7%, Val Loss: 1.487, Val Acc: 46.0%\n",
            "Epoch 2: Train Loss: 1.394, Train Acc: 49.9%, Val Loss: 1.329, Val Acc: 52.7%\n",
            "Epoch 3: Train Loss: 1.244, Train Acc: 55.9%, Val Loss: 1.266, Val Acc: 54.9%\n",
            "Epoch 4: Train Loss: 1.142, Train Acc: 59.6%, Val Loss: 1.216, Val Acc: 57.3%\n",
            "Epoch 5: Train Loss: 1.069, Train Acc: 62.4%, Val Loss: 1.184, Val Acc: 58.6%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>train_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>val_loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_accuracy</td><td>62.355</td></tr><tr><td>train_loss</td><td>1.06907</td></tr><tr><td>val_accuracy</td><td>58.65</td></tr><tr><td>val_loss</td><td>1.18392</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">polar-terrain-1</strong> at: <a href='https://wandb.ai/kevinantony-nit-jalandhar/Tier-1-Test/runs/d5a41cpr' target=\"_blank\">https://wandb.ai/kevinantony-nit-jalandhar/Tier-1-Test/runs/d5a41cpr</a><br> View project at: <a href='https://wandb.ai/kevinantony-nit-jalandhar/Tier-1-Test' target=\"_blank\">https://wandb.ai/kevinantony-nit-jalandhar/Tier-1-Test</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250228_164918-d5a41cpr/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the code, I identified several issues that need to be fixed:\n",
        "\n",
        "1.   In the data preprocessing, you're using a different transform for the CIFAR10 dataset than what you defined.\n",
        "2.   The `Network` class has errors in the architecture\n",
        "3.   The optimization parameters need adjustment\n",
        "4.   The training loop is missing some critical steps\n",
        "5.   Accuracy calculation and logging are missing\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XSWt2qHFX9et"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My Approach to Debugging the ML Pipeline:**\n",
        "\n",
        "I identified and fixed several critical issues in the ML pipeline:\n",
        "\n",
        "1.  Fixed the transform to properly normalize CIFAR10 (which has 3 channels, not 1)\n",
        "2.  Corrected the model architecture, particularly fixing `MaxPool2d`, properly calculating the flattened dimension size, and using `torch.flatten`\n",
        "3.  Reduced the learning rate from 1e3 (1000) to 0.01, which was causing instability\n",
        "4.  Added `optimizer.zero_grad()` in the training loop to prevent accumulating gradients\n",
        "5.  Implemented proper accuracy calculation and logging for both training and validation sets\n",
        "6.  Added proper logging of hyperparameters and metrics to Weights & Biases\n",
        "\n"
      ],
      "metadata": {
        "id": "oagNCz2s2Czh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2\n",
        "\n",
        "For this section, your task is to write code which can solve the following problem. We have provided a few unit tests to aid you with your task, but these are not comprehensive and you *should* write a few tests of your own to make sure your task runs perfectly.\n",
        "\n",
        "\n",
        "```\n",
        "Write a program to calculate the nth root of a given number x. You will be given the variables x and n. Your root should be close to the true value to atleast 2 decimal points of precision.\n",
        "\n",
        "Constraints:\n",
        "- You are NOT allowed to use exp(), pow(), the exponentiation operator (**) or any pre-built exponentiation methods.\n",
        "- x is guaranteed to be a positive real number.\n",
        "- n is guaranteed to be a positive integer.\n",
        "```"
      ],
      "metadata": {
        "id": "JTp5MVyVfMNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def root(x: float, n: int):\n",
        "    \"\"\"\n",
        "    Calculate the nth root of x using Newton's method.\n",
        "\n",
        "    Args:\n",
        "        x: positive real number\n",
        "        n: positive integer\n",
        "\n",
        "    Returns:\n",
        "        The nth root of x with at least 2 decimal places of precision\n",
        "    \"\"\"\n",
        "    # Handle edge cases\n",
        "    if x == 0:\n",
        "        return 0\n",
        "    if x == 1 or n == 1:\n",
        "        return x\n",
        "\n",
        "    # Initial guess - a reasonable starting point helps convergence\n",
        "    guess = x / n\n",
        "\n",
        "    # Precision threshold\n",
        "    epsilon = 1e-10\n",
        "\n",
        "    # Newton's method implementation\n",
        "    while True:\n",
        "        # Formula: x_{n+1} = ((n-1) * x_n + num / (x_n)^(n-1)) / n\n",
        "        # This avoids using ** for exponentiation\n",
        "\n",
        "        # Calculate x_n^(n-1) without using **\n",
        "        power = 1\n",
        "        for _ in range(n-1):\n",
        "            power *= guess\n",
        "\n",
        "        # Apply Newton's method formula\n",
        "        next_guess = ((n - 1) * guess + x / power) / n\n",
        "\n",
        "        # Check for convergence\n",
        "        if abs(next_guess - guess) < epsilon:\n",
        "            break\n",
        "\n",
        "        guess = next_guess\n",
        "\n",
        "    return guess"
      ],
      "metadata": {
        "id": "iuZQlY14lDdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My Approach to the Nth Root Problem**\n",
        "\n",
        "To calculate the nth root without using exponentiation operators:\n",
        "\n",
        "1.  I implemented Newton's method, which is an efficient iterative approach for finding roots\n",
        "2.  The key formula I used is: `x_{n+1} = ((n-1) * x_n + num / (x_n)^(n-1)) / n`\n",
        "3.  To calculate powers without using `**`, I implemented a simple loop that multiplies the base by itself n-1 times\n",
        "4.  I added handling for edge cases like x=0, x=1, and n=1\n",
        "5.  I implemented additional tests beyond the provided ones to verify correctness across a wider range of inputs\n",
        "\n",
        "**Note:**\n",
        "The implementation has O(log(x)) complexity in terms of the number of iterations needed for convergence, and each iteration takes O(n) time to calculate the power, making it efficient for both small and large values.\n"
      ],
      "metadata": {
        "id": "0zocUunS2iHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unit Tests\n",
        "\n",
        "(You are allowed to use pre built exponentiation methods to test against)"
      ],
      "metadata": {
        "id": "heFr3c0jl3m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_tests():\n",
        "    THRESHOLD = 1e-2\n",
        "\n",
        "    def is_approximately_equal(a, b):\n",
        "        return abs(a - b) <= THRESHOLD\n",
        "\n",
        "    # Original tests\n",
        "    assert is_approximately_equal(root(100, 2), 100 ** 0.5)\n",
        "    assert is_approximately_equal(root(50, 2), 50 ** 0.5)\n",
        "    assert is_approximately_equal(root(30, 5), 30 ** 0.2)\n",
        "    assert is_approximately_equal(root(1, 2), 1)\n",
        "\n",
        "    # Additional tests\n",
        "    assert is_approximately_equal(root(8, 3), 2.0)  # Cube root of 8 is 2\n",
        "    assert is_approximately_equal(root(16, 4), 2.0)  # 4th root of 16 is 2\n",
        "    assert is_approximately_equal(root(1000000, 6), 10.0)  # 6th root of 1,000,000 is 10\n",
        "    assert is_approximately_equal(root(2, 1), 2.0)  # 1st root is the number itself\n",
        "    assert is_approximately_equal(root(0.25, 2), 0.5)  # Square root of 0.25 is 0.5\n",
        "    assert is_approximately_equal(root(27, 3), 3.0)  # Cube root of 27 is 3\n",
        "\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "# Run the tests\n",
        "run_tests()\n"
      ],
      "metadata": {
        "id": "WJNwAkTtl1V3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc55c349-43dd-4c99-c147-a96095e88a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Additional Info**"
      ],
      "metadata": {
        "id": "ygUait1k4Y67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 1:**"
      ],
      "metadata": {
        "id": "ufgbUrGc4fA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  **Data Augmentation:** Consider adding data augmentation to improve model performance."
      ],
      "metadata": {
        "id": "FDGTmujC4lfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "hpDEnml54re5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Learning Rate Scheduler:** Add a learning rate scheduler to improve convergence:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LpiDZt5a4v4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
        "# Add scheduler.step() at the end of each epoch"
      ],
      "metadata": {
        "id": "DgmAHHaw45FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  **Batch Normalization:** Adding batch normalization to the model could improve training stability and speed up convergence:\n"
      ],
      "metadata": {
        "id": "JxepgJIw49OR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "self.bn1 = nn.BatchNorm2d(6)\n",
        "# Then in forward: x = self.pool(F.relu(self.bn1(self.conv1(x))))"
      ],
      "metadata": {
        "id": "ekuWa-Nu5BtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  **Model Saving:** Consider adding code to save the best model based on validation accuracy:\n"
      ],
      "metadata": {
        "id": "ROh7oZ9b5D_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc = 0\n",
        "# Within your validation loop:\n",
        "if val_accuracy > best_val_acc:\n",
        "    best_val_acc = val_accuracy\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), 'best_model.pth')\n",
        "    wandb.save('best_model.pth')"
      ],
      "metadata": {
        "id": "Cg43UMcH5NXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 2:**"
      ],
      "metadata": {
        "id": "8OpoF5HG5hzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  **Efficiency:** Could be optimized by tracking the power as you go"
      ],
      "metadata": {
        "id": "IxcAHQa156OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of recalculating the power each time\n",
        "prev_power = 1\n",
        "for _ in range(n-1):\n",
        "    prev_power *= guess\n",
        "\n",
        "# Then for the next iteration, you could do:\n",
        "next_power = 1\n",
        "for _ in range(n-1):\n",
        "    next_power *= next_guess"
      ],
      "metadata": {
        "id": "pBN4m1p65t1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **More Edge Cases**: Could consider handling very large values of x or n:"
      ],
      "metadata": {
        "id": "Jbwxe-hm6DwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For very large values of x, adjust initial guess\n",
        "if x > 1e10:\n",
        "    guess = x / (2 * n)  # Might converge better for large values"
      ],
      "metadata": {
        "id": "AKFLIny16JwN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}